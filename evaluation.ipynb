{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[언어모델 평가방법](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [언어모델 평가방법](#toc1_1_)    \n",
    "    - [PPL(perplexity)](#toc1_1_1_)    \n",
    "    - [보정된 유니그램 정밀도(Modified Unigram Precision)](#toc1_1_2_)    \n",
    "    - [BLUE(Bilingual Evaluation Understudy)](#toc1_1_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[PPL(perplexity)](#toc0_)\n",
    "- 불확실성을 수치화\n",
    "- 예측대상의 확률분포가 비슷하다면, 불확실성이 높기 때문에 성능이 낮다고 간주 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[보정된 유니그램 정밀도(Modified Unigram Precision)](#toc0_)\n",
    "- 기계번역을 예측값, 사람번역을 실제값이라고 할 때, \n",
    "- 예측값에서 각 단어가 사용된 횟수보다 실제값에서 사용된 횟수가 더 유의미하다고 간주하여\n",
    "- 이 두값을 스케일링\n",
    "- $Count_{clip}\\ =\\ min(Count,\\ Max)$\n",
    "- $\\text{Modified Unigram Precision =}\\frac{\\sum_{unigram∈Candidate}\\ Count_{clip}(unigram)}\n",
    "{\\sum_{unigram∈Candidate}\\ Count(unigram)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장에서 n-gram 카운트\n",
    "# 예측값(번역값)에서 각 단어가 사용된 횟수수\n",
    "def simple_count(tokens,n):\n",
    "    return Counter(ngrams(tokens,n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니그램 카운트 : Counter({('the',): 3, ('It',): 1, ('is',): 1, ('a',): 1, ('guide',): 1, ('to',): 1, ('action',): 1, ('which',): 1, ('ensures',): 1, ('that',): 1, ('military',): 1, ('always',): 1, ('obeys',): 1, ('commands',): 1, ('of',): 1, ('party.',): 1})\n"
     ]
    }
   ],
   "source": [
    "candidate = \"It is a guide to action which ensures that the military always obeys the commands of the party.\"\n",
    "tokens = candidate.split() # 토큰화\n",
    "result = simple_count(tokens, 1) # n = 1은 유니그램\n",
    "print('유니그램 카운트 :',result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니그램 카운트 : Counter({('the',): 7})\n"
     ]
    }
   ],
   "source": [
    "candidate = 'the the the the the the the'\n",
    "tokens = candidate.split() # 토큰화\n",
    "result = simple_count(tokens, 1) # n = 1은 유니그램\n",
    "print('유니그램 카운트 :',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값의 각 단어가 실제값(사람번역)에 사용된 횟수\n",
    "# 즉, 단어의 실효성을 카운트하여 추출\n",
    "\n",
    "def count_clip(candiate, reference_list,n):\n",
    "    # Ca 문장에서 n-gram 카운트\n",
    "    ca_cnt = simple_count(candiate, n)\n",
    "    max_ref_cnt_dict = dict()\n",
    "\n",
    "    \n",
    "    for ref in reference_list:\n",
    "        # ref 문장에서 n-gram 카운트\n",
    "        ref_cnt = simple_count(ref,n) # ref_cnt : Counter({('the',): 2, ('cat',): 1, ('is',): 1, ('on',): 1, ('mat',): 1})\n",
    "        print(ref_cnt)\n",
    "\n",
    "        # ref 문장에서 n-gram의 최대 등장 횟수 계산\n",
    "        for n_gram in ref_cnt: \n",
    "            if n_gram in max_ref_cnt_dict: # n_gram : ('the',)\n",
    "                print(n_gram)\n",
    "                max_ref_cnt_dict[n_gram] = max(ref_cnt[n_gram], max_ref_cnt_dict[n_gram])\n",
    "            else:\n",
    "                max_ref_cnt_dict[n_gram] = ref_cnt[n_gram]\n",
    "\n",
    "    return {\n",
    "        # count_clip = min(count, max_ref_count)\n",
    "        # ca_cnt.get(n_gram,0) : ca_cnt 에서 n_gram값을 출력하되, 없으면 0을 반환환\n",
    "        n_gram: min(ca_cnt.get(n_gram, 0), max_ref_cnt_dict.get(n_gram, 0)) for n_gram in ca_cnt\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=Counter({('the',): 2, ('cat',): 1, ('is',): 1, ('on',): 1, ('mat',): 1})\n",
    "for w in a:\n",
    "    word = w\n",
    "a.get('the',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the',): 2, ('cat',): 1, ('is',): 1, ('on',): 1, ('mat',): 1})\n",
      "Counter({('there',): 1, ('is',): 1, ('a',): 1, ('cat',): 1, ('on',): 1, ('the',): 1, ('mat',): 1})\n",
      "('is',)\n",
      "('cat',)\n",
      "('on',)\n",
      "('the',)\n",
      "('mat',)\n",
      "보정된 유니그램 카운트 : {('the',): 2}\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "# 예측값에서 'the'는 7번 사용되었으나\n",
    "# 실제값에서는 최대 2번 사용되었으므로 이 값을 유의미한 횟수로 간주한다\n",
    "#  \n",
    "candidate = 'the the the the the the the'\n",
    "references = [\n",
    "    'the cat is on the mat',\n",
    "    'there is a cat on the mat'\n",
    "]\n",
    "result = count_clip(candidate.split(),list(map(lambda ref: ref.split(), references)),1)\n",
    "print('보정된 유니그램 카운트 :',result)\n",
    "\n",
    "# map() 함수는 iterable(반복 가능한 객체)의 각 요소에 function을 적용하여 새로운 map 객체를 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_precision(candidate, reference_list, n):\n",
    "  clip_cnt = count_clip(candidate, reference_list, n) \n",
    "  total_clip_cnt = sum(clip_cnt.values()) # 분자\n",
    "\n",
    "  cnt = simple_count(candidate, n)\n",
    "  total_cnt = sum(cnt.values()) # 분모\n",
    "\n",
    "  # 분모가 0이 되는 것을 방지\n",
    "  if total_cnt == 0: \n",
    "    total_cnt = 1\n",
    "\n",
    "  # 분자 : count_clip의 합, 분모 : 단순 count의 합 ==> 보정된 정밀도\n",
    "  return (total_clip_cnt / total_cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the',): 2, ('cat',): 1, ('is',): 1, ('on',): 1, ('mat',): 1})\n",
      "Counter({('there',): 1, ('is',): 1, ('a',): 1, ('cat',): 1, ('on',): 1, ('the',): 1, ('mat',): 1})\n",
      "('is',)\n",
      "('cat',)\n",
      "('on',)\n",
      "('the',)\n",
      "('mat',)\n",
      "보정된 유니그램 정밀도 : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "result = modified_precision(candidate.split(), list(map(lambda ref: ref.split(), references)), n=1)\n",
    "print('보정된 유니그램 정밀도 :',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[BLUE(Bilingual Evaluation Understudy)](#toc0_)\n",
    "- 순서정보를 고려하기 위해 유니그램(p1)에서 n-gram(pn)으로 확장\n",
    "- $p_{n}=\\frac{\\sum_{n\\text{-}gram∈Candidate}\\ Count_{clip}(n\\text{-}gram)}\n",
    "{\\sum_{n\\text{-}gram∈Candidate}\\ Count(n\\text{-}gram)}$\n",
    "- $BLEU = exp(\\sum_{n=1}^{N}w_{n}\\ \\text{log}\\ p_{n})$<br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 예측값의 문장길이가 긴 경우, n-gram 순서정보로 인해 패널티가 적용됨\n",
    "- 반면, 예측값의 문장길이가 짧은 경우, 높은 점수를 얻을 수 있기 때문에 별도의 패널티 부여 필요\n",
    "- 이를 브레버티 패널티(Brevity Penalty) 라고 한다\n",
    "\n",
    "\n",
    "- $BLEU = BP × exp(\\sum_{n=1}^{N}w_{n}\\ \\text{log}\\ p_{n})$\n",
    "- $BP = \\begin{cases}1&\\text{if}\\space c>r\\\\ e^{(1-r/c)}&\\text{if}\\space c \\leq r \\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수\n",
    "def closest_ref_length(candidate, reference_list):\n",
    "  ca_len = len(candidate) # ca 길이\n",
    "  ref_lens = (len(ref) for ref in reference_list) # Ref들의 길이\n",
    "  # 길이 차이를 최소화하는 Ref를 찾아서 Ref의 길이를 리턴\n",
    "  closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))\n",
    "  return closest_ref_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate, reference_list):\n",
    "  ca_len = len(candidate)\n",
    "  ref_len = closest_ref_length(candidate, reference_list)\n",
    "\n",
    "  if ca_len > ref_len:\n",
    "    return 1\n",
    "\n",
    "  # candidate가 비어있다면 BP = 0 → BLEU = 0.0\n",
    "  elif ca_len == 0 :\n",
    "    return 0\n",
    "  else:\n",
    "    return np.exp(1 - ref_len/ca_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(candidate, reference_list, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "  bp = brevity_penalty(candidate, reference_list) # 브레버티 패널티, BP\n",
    "\n",
    "  p_n = [modified_precision(candidate, reference_list, n=n) for n, _ in enumerate(weights,start=1)] \n",
    "  # p1, p2, p3, ..., pn\n",
    "  score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n",
    "  return bp * np.exp(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('that',): 2, ('It',): 1, ('is',): 1, ('a',): 1, ('guide',): 1, ('to',): 1, ('action',): 1, ('ensures',): 1, ('the',): 1, ('military',): 1, ('will',): 1, ('forever',): 1, ('heed',): 1, ('Party',): 1, ('commands',): 1})\n",
      "Counter({('the',): 4, ('It',): 1, ('is',): 1, ('guiding',): 1, ('principle',): 1, ('which',): 1, ('guarantees',): 1, ('military',): 1, ('forces',): 1, ('always',): 1, ('being',): 1, ('under',): 1, ('command',): 1, ('of',): 1, ('Party',): 1})\n",
      "('It',)\n",
      "('is',)\n",
      "('the',)\n",
      "('military',)\n",
      "('Party',)\n",
      "Counter({('the',): 4, ('It',): 1, ('is',): 1, ('practical',): 1, ('guide',): 1, ('for',): 1, ('army',): 1, ('always',): 1, ('to',): 1, ('heed',): 1, ('directions',): 1, ('of',): 1, ('party',): 1})\n",
      "('It',)\n",
      "('is',)\n",
      "('the',)\n",
      "('guide',)\n",
      "('always',)\n",
      "('to',)\n",
      "('heed',)\n",
      "('of',)\n",
      "Counter({('It', 'is'): 1, ('is', 'a'): 1, ('a', 'guide'): 1, ('guide', 'to'): 1, ('to', 'action'): 1, ('action', 'that'): 1, ('that', 'ensures'): 1, ('ensures', 'that'): 1, ('that', 'the'): 1, ('the', 'military'): 1, ('military', 'will'): 1, ('will', 'forever'): 1, ('forever', 'heed'): 1, ('heed', 'Party'): 1, ('Party', 'commands'): 1})\n",
      "Counter({('It', 'is'): 1, ('is', 'the'): 1, ('the', 'guiding'): 1, ('guiding', 'principle'): 1, ('principle', 'which'): 1, ('which', 'guarantees'): 1, ('guarantees', 'the'): 1, ('the', 'military'): 1, ('military', 'forces'): 1, ('forces', 'always'): 1, ('always', 'being'): 1, ('being', 'under'): 1, ('under', 'the'): 1, ('the', 'command'): 1, ('command', 'of'): 1, ('of', 'the'): 1, ('the', 'Party'): 1})\n",
      "('It', 'is')\n",
      "('the', 'military')\n",
      "Counter({('It', 'is'): 1, ('is', 'the'): 1, ('the', 'practical'): 1, ('practical', 'guide'): 1, ('guide', 'for'): 1, ('for', 'the'): 1, ('the', 'army'): 1, ('army', 'always'): 1, ('always', 'to'): 1, ('to', 'heed'): 1, ('heed', 'the'): 1, ('the', 'directions'): 1, ('directions', 'of'): 1, ('of', 'the'): 1, ('the', 'party'): 1})\n",
      "('It', 'is')\n",
      "('is', 'the')\n",
      "('of', 'the')\n",
      "Counter({('It', 'is', 'a'): 1, ('is', 'a', 'guide'): 1, ('a', 'guide', 'to'): 1, ('guide', 'to', 'action'): 1, ('to', 'action', 'that'): 1, ('action', 'that', 'ensures'): 1, ('that', 'ensures', 'that'): 1, ('ensures', 'that', 'the'): 1, ('that', 'the', 'military'): 1, ('the', 'military', 'will'): 1, ('military', 'will', 'forever'): 1, ('will', 'forever', 'heed'): 1, ('forever', 'heed', 'Party'): 1, ('heed', 'Party', 'commands'): 1})\n",
      "Counter({('It', 'is', 'the'): 1, ('is', 'the', 'guiding'): 1, ('the', 'guiding', 'principle'): 1, ('guiding', 'principle', 'which'): 1, ('principle', 'which', 'guarantees'): 1, ('which', 'guarantees', 'the'): 1, ('guarantees', 'the', 'military'): 1, ('the', 'military', 'forces'): 1, ('military', 'forces', 'always'): 1, ('forces', 'always', 'being'): 1, ('always', 'being', 'under'): 1, ('being', 'under', 'the'): 1, ('under', 'the', 'command'): 1, ('the', 'command', 'of'): 1, ('command', 'of', 'the'): 1, ('of', 'the', 'Party'): 1})\n",
      "Counter({('It', 'is', 'the'): 1, ('is', 'the', 'practical'): 1, ('the', 'practical', 'guide'): 1, ('practical', 'guide', 'for'): 1, ('guide', 'for', 'the'): 1, ('for', 'the', 'army'): 1, ('the', 'army', 'always'): 1, ('army', 'always', 'to'): 1, ('always', 'to', 'heed'): 1, ('to', 'heed', 'the'): 1, ('heed', 'the', 'directions'): 1, ('the', 'directions', 'of'): 1, ('directions', 'of', 'the'): 1, ('of', 'the', 'party'): 1})\n",
      "('It', 'is', 'the')\n",
      "Counter({('It', 'is', 'a', 'guide'): 1, ('is', 'a', 'guide', 'to'): 1, ('a', 'guide', 'to', 'action'): 1, ('guide', 'to', 'action', 'that'): 1, ('to', 'action', 'that', 'ensures'): 1, ('action', 'that', 'ensures', 'that'): 1, ('that', 'ensures', 'that', 'the'): 1, ('ensures', 'that', 'the', 'military'): 1, ('that', 'the', 'military', 'will'): 1, ('the', 'military', 'will', 'forever'): 1, ('military', 'will', 'forever', 'heed'): 1, ('will', 'forever', 'heed', 'Party'): 1, ('forever', 'heed', 'Party', 'commands'): 1})\n",
      "Counter({('It', 'is', 'the', 'guiding'): 1, ('is', 'the', 'guiding', 'principle'): 1, ('the', 'guiding', 'principle', 'which'): 1, ('guiding', 'principle', 'which', 'guarantees'): 1, ('principle', 'which', 'guarantees', 'the'): 1, ('which', 'guarantees', 'the', 'military'): 1, ('guarantees', 'the', 'military', 'forces'): 1, ('the', 'military', 'forces', 'always'): 1, ('military', 'forces', 'always', 'being'): 1, ('forces', 'always', 'being', 'under'): 1, ('always', 'being', 'under', 'the'): 1, ('being', 'under', 'the', 'command'): 1, ('under', 'the', 'command', 'of'): 1, ('the', 'command', 'of', 'the'): 1, ('command', 'of', 'the', 'Party'): 1})\n",
      "Counter({('It', 'is', 'the', 'practical'): 1, ('is', 'the', 'practical', 'guide'): 1, ('the', 'practical', 'guide', 'for'): 1, ('practical', 'guide', 'for', 'the'): 1, ('guide', 'for', 'the', 'army'): 1, ('for', 'the', 'army', 'always'): 1, ('the', 'army', 'always', 'to'): 1, ('army', 'always', 'to', 'heed'): 1, ('always', 'to', 'heed', 'the'): 1, ('to', 'heed', 'the', 'directions'): 1, ('heed', 'the', 'directions', 'of'): 1, ('the', 'directions', 'of', 'the'): 1, ('directions', 'of', 'the', 'party'): 1})\n",
      "실습 코드의 BLEU : 0.5045666840058485\n",
      "패키지 NLTK의 BLEU : 0.5045666840058485\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "references = [\n",
    "    'It is a guide to action that ensures that the military will forever heed Party commands',\n",
    "    'It is the guiding principle which guarantees the military forces always being under the command of the Party',\n",
    "    'It is the practical guide for the army always to heed the directions of the party'\n",
    "]\n",
    "\n",
    "print('실습 코드의 BLEU :',bleu_score(candidate.split(),list(map(lambda ref: ref.split(), references))))\n",
    "print('패키지 NLTK의 BLEU :',bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH38_CPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
